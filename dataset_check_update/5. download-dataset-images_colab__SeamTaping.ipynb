{"cells":[{"cell_type":"markdown","metadata":{"id":"C6N5z5Tr34PM"},"source":["## Download the Dataset Images to Google Drive\n","\n","In order to work TorchVision FasterRCNN and YOLO on google colab, we should download dataset images to google drive.\n","\n","- Create a folder \"**CrackDetection**\" on your google drive ([My Drive](https://drive.google.com/drive/u/0/my-drive))\n","- Upload this notebook and dataset JSON file '**WRB_All_bbox_annotations.json**' from your local to the created gdrive folder \"**CrackDetection**\"\n","- Then run this notebook.\n","    * When runing the first time, you need to allow colab access to your google drive.\n","    * When start running, please check the \"project_name\" variable setting."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xp7_LAP7pBKE","executionInfo":{"status":"ok","timestamp":1720044842993,"user_tz":180,"elapsed":478,"user":{"displayName":"Sanhyew Ng","userId":"11208097760017685523"}},"outputId":"f7ef2710-414d-43f2-c586-7916d553bad8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Project: SeamTaping\n"]}],"source":["project_name = \"SeamTaping\"\n","# project_name = \"WRB\"\n","\n","print(\"Project:\", project_name)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ru8EqqJIpBKF","executionInfo":{"status":"ok","timestamp":1720044883357,"user_tz":180,"elapsed":39906,"user":{"displayName":"Sanhyew Ng","userId":"11208097760017685523"}},"outputId":"6642682f-8380-4bea-d7ef-7d3a05dd7714"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Directory already exists: /content/gdrive/MyDrive/CrackDetection/SeamTaping_dataset/images\n"]}],"source":["import json\n","import os\n","import requests\n","from tqdm import tqdm\n","import time\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","project_dataset_folder = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_dataset'\n","\n","# Path to save images\n","image_folder = project_dataset_folder + '/images'\n","\n","# Check if image_folder already exists\n","if not os.path.exists(image_folder):\n","    os.makedirs(image_folder)\n","    print(f\"Created directory: {image_folder}\")\n","else:\n","    print(f\"Directory already exists: {image_folder}\")\n","\n","# Load dataset from JSON\n","dataset_json_path = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_All_bbox_annotations.json'\n","with open(dataset_json_path, 'r') as f:\n","    dataset = json.load(f)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Fe4tCe-34PP","outputId":"8f89f78e-f6e5-4133-b26c-0d22553f7d9b","executionInfo":{"status":"ok","timestamp":1720044884376,"user_tz":180,"elapsed":1026,"user":{"displayName":"Sanhyew Ng","userId":"11208097760017685523"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 223/223 [00:00<00:00, 307.06it/s]\n"]}],"source":["# Function to download image from URL with retries\n","def download_image(url, save_path, retries=3, retry_delay=2):\n","    attempt = 0\n","    while attempt < retries:\n","        try:\n","            response = requests.get(url, stream=True)\n","            if response.status_code == 200:\n","                with open(save_path, 'wb') as file:\n","                    for chunk in response.iter_content(chunk_size=1024):\n","                        if chunk:\n","                            file.write(chunk)\n","                return True\n","            else:\n","                print(f\"Failed to download image from {url}. Status code: {response.status_code}\")\n","        except Exception as e:\n","            print(f\"Exception occurred while downloading image from {url}: {e}\")\n","\n","        attempt += 1\n","        time.sleep(retry_delay)\n","\n","    print(f\"Failed to download image from {url} after {retries} attempts.\")\n","    return False\n","\n","# Download images with tqdm progress bar\n","for data in tqdm(dataset):\n","    image_urls = data['image_urls']\n","    image_file_name = data['image_file_name']\n","    image_save_path = os.path.join(image_folder, image_file_name)\n","\n","    # Check if file already exists\n","    if os.path.exists(image_save_path):\n","        # print(f\"Skipping download of {image_file_name}. File already exists.\")\n","        continue\n","\n","    # Download only the first URL\n","    success = download_image(image_urls[0], image_save_path)\n","    if not success:\n","        print(f\"Failed to download {image_file_name} from {image_urls[0]}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARDT5PPgOsyx","outputId":"fbf57278-0299-486f-b470-fa2f42d21b61","executionInfo":{"status":"ok","timestamp":1720044884377,"user_tz":180,"elapsed":13,"user":{"displayName":"Sanhyew Ng","userId":"11208097760017685523"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Total number of image files in /content/gdrive/MyDrive/CrackDetection/SeamTaping_dataset/images: 223\n"]}],"source":["# Count number of image files in directory\n","num_images = len([name for name in os.listdir(image_folder)\n","                      if os.path.isfile(os.path.join(image_folder, name)) and\n","                         name.lower().endswith(('.png', '.jpg', '.jpeg'))\n","                 ])\n","print(f\"\\nTotal number of image files in {image_folder}: {num_images}\")"]},{"cell_type":"markdown","metadata":{"id":"NdCH1JFspBKH"},"source":["### Split dataset in json"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9B9zX-8pBKH","executionInfo":{"status":"ok","timestamp":1720044884377,"user_tz":180,"elapsed":9,"user":{"displayName":"Sanhyew Ng","userId":"11208097760017685523"}},"outputId":"78b23866-d775-46d5-c1ed-48db762b7536"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: 156 samples\n","Validation set: 33 samples\n","Test set: 34 samples\n"]}],"source":["import json\n","import random\n","\n","# Shuffle the dataset\n","random.shuffle(dataset)\n","\n","# Define split ratios\n","train_ratio = 0.7\n","val_ratio = 0.15\n","test_ratio = 0.15\n","\n","# Calculate lengths of each partition\n","num_samples = len(dataset)\n","num_train = int(train_ratio * num_samples)\n","num_val = int(val_ratio * num_samples)\n","\n","# Split the dataset\n","train_data = dataset[:num_train]\n","val_data = dataset[num_train:num_train+num_val]\n","test_data = dataset[num_train+num_val:]\n","\n","# Write partitioned data to new JSON files or keep them in memory\n","with open(os.path.join(project_dataset_folder, 'train_data.json'), 'w') as f:\n","    json.dump(train_data, f, indent=4)\n","\n","with open(os.path.join(project_dataset_folder, 'val_data.json'), 'w') as f:\n","    json.dump(val_data, f, indent=4)\n","\n","with open(os.path.join(project_dataset_folder, 'test_data.json'), 'w') as f:\n","    json.dump(test_data, f, indent=4)\n","\n","# Print lengths of each partition\n","print(f\"Training set: {len(train_data)} samples\")\n","print(f\"Validation set: {len(val_data)} samples\")\n","print(f\"Test set: {len(test_data)} samples\")"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}