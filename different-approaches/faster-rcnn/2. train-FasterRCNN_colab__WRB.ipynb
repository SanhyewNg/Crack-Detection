{"cells":[{"cell_type":"markdown","metadata":{"id":"x1-Xf8_oClDx"},"source":["## Setup Google Colab\n","\n","First, mount Google Drive to access files:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2BoLZEoClD2","executionInfo":{"status":"ok","timestamp":1720082822445,"user_tz":180,"elapsed":5119,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}},"outputId":"f4b3d607-0627-419f-abc6-3c7a2d07713e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Project: WRB\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# project_name = \"SeamTaping\"\n","project_name = \"WRB\"\n","print(\"Project:\", project_name)\n","\n","# Path to saved images\n","image_folder = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_dataset/images'\n","\n","# Load dataset from JSON\n","train_dataset_json_path = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_dataset/train_data.json'\n","val_dataset_json_path = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_dataset/val_data.json'\n","test_dataset_json_path = f'/content/gdrive/MyDrive/CrackDetection/{project_name}_dataset/test_data.json'\n"]},{"cell_type":"markdown","metadata":{"id":"6UvHiREqClD4"},"source":["## Define Custom Dataset Class\n","\n","Create a custom dataset class to load images and annotations."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"jFgyqDEMClD4","executionInfo":{"status":"ok","timestamp":1720087533683,"user_tz":180,"elapsed":450,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}}},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","import torch\n","from PIL import Image, ImageDraw\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataset_json_path, image_folder):\n","        with open(dataset_json_path, 'r') as f:\n","            dataset = json.load(f)\n","\n","        self.dataset = dataset\n","        self.image_folder = image_folder\n","        self.mean = [0.485, 0.456, 0.406]\n","        self.std = [0.229, 0.224, 0.225]\n","        self.image_size = (800, 800)\n","        self.transforms = T.Compose([\n","            T.Resize(self.image_size),\n","            T.ToTensor(),\n","            T.Normalize(mean=self.mean, std=self.std)\n","        ])\n","\n","        self.label_map = {\n","            'WRB-Bad': 1,\n","            # Add more labels as needed\n","        }\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def xywh_to_xyxy(self, xywh):\n","        x, y, w, h = xywh\n","        x2 = x + w\n","        y2 = y + h\n","        xyxy = [x, y, x2, y2]\n","        return xyxy\n","\n","    def __getitem__(self, idx):\n","        image_data = self.dataset[idx]\n","        image_file_name = image_data['image_file_name']\n","        image_path = os.path.join(self.image_folder, image_file_name)\n","\n","        # Load image\n","        image_original = Image.open(image_path).convert(\"RGB\")\n","        # Apply transformations\n","        if self.transforms is not None:\n","            image = self.transforms(image_original)\n","\n","        # Calculate scaling factor for resizing bounding boxes AFTER transforms\n","        original_size = np.array(image_original.size)  # Get original size from the image file\n","        # print(original_size)\n","        resized_size = self.image_size\n","        scale = resized_size / original_size\n","        # print(scale)\n","\n","\n","        # Get bounding boxes and labels\n","        boxes = []\n","        labels = []\n","        for annotation in image_data['annotations']:\n","            bbox = annotation['bbox']\n","            box = self.xywh_to_xyxy(bbox)\n","            # Adjust bounding box coordinates based on resizing\n","            box[0] *= scale[0]  # x_min\n","            box[1] *= scale[1]  # y_min\n","            box[2] *= scale[0]  # x_max\n","            box[3] *= scale[1]  # y_max\n","\n","            boxes.append(box)\n","            labels.append(self.label_map[annotation['label']])\n","\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        labels = torch.tensor(labels, dtype=torch.int64)\n","        target = {\n","            'boxes': boxes,\n","            'labels': labels\n","        }\n","\n","        return image, target\n","\n","# Create custom dataset instance with augmentation enabled\n","train_dataset = CustomDataset(train_dataset_json_path, image_folder)\n","val_dataset = CustomDataset(val_dataset_json_path, image_folder)\n","test_dataset = CustomDataset(test_dataset_json_path, image_folder)\n","\n","def collate_fn(batch):\n","    images = [item[0] for item in batch]\n","    targets = [item[1] for item in batch]\n","\n","    # Assuming targets is a list of dictionaries\n","    for idx, target in enumerate(targets):\n","        # Convert target to a format suitable for the model\n","        targets[idx] = {\n","            'boxes': target['boxes'].clone().detach().to(torch.float32),  # Ensure boxes are float32\n","            'labels': target['labels'].clone().detach().to(torch.int64),  # Ensure boxes are int64\n","            # Add other keys as necessary (e.g., masks, keypoints)\n","        }\n","\n","    return images, targets\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n","val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n"]},{"cell_type":"markdown","metadata":{"id":"uu24PpE2ClD6"},"source":["## Train TorchVision FasterRCNN model"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"k3U2um7zClD7","executionInfo":{"status":"ok","timestamp":1720082826941,"user_tz":180,"elapsed":15,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}}},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import torchvision\n","\n","def get_model(weights=None):\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=weights)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 2)\n","    return model"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0DPpeD9ClD7","outputId":"3dc07d71-9145-461d-b185-b0ca4d6eefe4","executionInfo":{"status":"ok","timestamp":1720087154383,"user_tz":180,"elapsed":4327454,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:31<00:00,  1.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [02:37<00:00,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.3706, Val Loss: 0.3401, Learning Rate: 0.005000\n","Epoch 2/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.3029, Val Loss: 0.3134, Learning Rate: 0.000500\n","Epoch 3/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2416, Val Loss: 0.2917, Learning Rate: 0.000500\n","Epoch 4/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2247, Val Loss: 0.3034, Learning Rate: 0.000050\n","Epoch 5/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:12<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2124, Val Loss: 0.3130, Learning Rate: 0.000050\n","Epoch 6/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2113, Val Loss: 0.3149, Learning Rate: 0.000005\n","Epoch 7/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2077, Val Loss: 0.3150, Learning Rate: 0.000005\n","Epoch 8/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:48<00:00,  3.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2080, Val Loss: 0.3154, Learning Rate: 0.000001\n","Epoch 9/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:13<00:00,  1.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2076, Val Loss: 0.3146, Learning Rate: 0.000001\n","Epoch 10/10\n","Training \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 734/734 [06:11<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validating \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 157/157 [00:47<00:00,  3.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss: 0.2073, Val Loss: 0.3155, Learning Rate: 0.000000\n","Training complete.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","from tqdm import tqdm\n","\n","def train_epoch(model, train_dataloader, optimizer, device):\n","    model.train()\n","    train_loss = 0\n","    print(\"Training \")\n","    for images, targets in tqdm(train_dataloader):\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        optimizer.zero_grad()\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","        losses.backward()\n","        optimizer.step()\n","\n","        train_loss += losses.item()\n","\n","    return train_loss / len(train_dataloader)\n","\n","def validate_epoch(model, val_dataloader, device):\n","# https://stackoverflow.com/questions/60339336/validation-loss-for-pytorch-faster-rcnn/65347721#65347721\n","    model.train()\n","    val_loss = 0\n","    print(\"Validating \")\n","    with torch.no_grad():\n","        for images, targets in tqdm(val_dataloader):\n","            images = list(image.to(device) for image in images)\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","            loss_dict = model(images, targets)\n","            losses = sum(loss for loss in loss_dict.values())\n","            val_loss += losses.item()\n","\n","    return val_loss / len(val_dataloader)\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = get_model(weights=\"DEFAULT\")\n","model.to(device)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)  # Adjust learning rate every 2 epochs\n","\n","num_epochs = 10\n","\n","train_losses = []\n","val_losses = []\n","learning_rates = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    train_loss = train_epoch(model, train_dataloader, optimizer, device)\n","    val_loss = validate_epoch(model, val_dataloader, device)\n","\n","    train_losses.append(train_loss)\n","    val_losses.append(val_loss)\n","\n","    current_lr = optimizer.param_groups[0]['lr']\n","    print(f\"\\tTrain Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Learning Rate: {current_lr:.6f}\")\n","    learning_rates.append(current_lr)\n","\n","    scheduler.step()  # Update learning rate\n","\n","\n","print(\"Training complete.\")\n"]},{"cell_type":"markdown","metadata":{"id":"wk34BqyHClD-"},"source":["### Save the Model\n","\n","Save the trained model."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ujTbaWtCClD-","executionInfo":{"status":"ok","timestamp":1720087185731,"user_tz":180,"elapsed":2132,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}}},"outputs":[],"source":["# Save model\n","checkpoint_dir = '/content/gdrive/MyDrive/CrackDetection'\n","torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'faster_rcnn_model_WRB.pth'))"]},{"cell_type":"markdown","metadata":{"id":"YoosJen0ClD-"},"source":["## Load and Evaluate the Model\n"]},{"cell_type":"markdown","metadata":{"id":"_JZBXA3CClD_"},"source":["### Load the model for inference."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"uH9Zkq2uClD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720087774398,"user_tz":180,"elapsed":1486,"user":{"displayName":"Ocean Star","userId":"01396959549972776402"}},"outputId":"4f1f871b-767f-4d1b-bd6d-c6dbe1b3f21e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (layer_blocks): ModuleList(\n","        (0-3): 4 x Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU(inplace=True)\n","        )\n","      )\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":16}],"source":["# Load model\n","model = get_model()\n","model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'faster_rcnn_model_WRB.pth')))\n","model.to(device)\n","model.eval()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}